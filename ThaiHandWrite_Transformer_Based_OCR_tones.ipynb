{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Watthana65022128/model-vit-vision-transformer/blob/main/ThaiHandWrite_Transformer_Based_OCR_tones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอนหลัก\n",
        "1.การเตรียมข้อมูล:\n",
        "\n",
        "แปลงภาพตัวอักษรภาษาไทยให้เป็นรูปแบบ Tensor ที่เหมาะสมสำหรับโมเดล Transformer\n",
        "จัดแบ่งข้อมูลเป็นชุด Train, Validation, และ Test\n",
        "การสร้างโมเดล OCR ด้วย Transformer:\n",
        "\n",
        "ใช้โมเดล Vision Transformer (ViT) หรือ Swin Transformer จากไลบรารี เช่น Hugging Face Transformers\n",
        "2.การฝึกโมเดล:\n",
        "\n",
        "กำหนด Loss Function และ Optimizer เพื่อปรับปรุงโมเดลให้เหมาะสม\n",
        "3.การประเมินผล:\n",
        "\n",
        "ใช้เมตริก เช่น Accuracy, Precision, Recall และ F1-score\n",
        "\n",
        "คำอธิบาย\n",
        "การเตรียมข้อมูล:\n",
        "\n",
        "ข้อมูลถูกแปลงเป็น Tensor ที่เหมาะสมสำหรับโมเดล Transformer โดยใช้ ViTFeatureExtractor\n",
        "การสร้างโมเดล:\n",
        "\n",
        "ใช้ Vision Transformer (google/vit-base-patch16-224) ที่ pretrained บน ImageNet และปรับแต่งให้รองรับจำนวนคลาสตัวอักษรไทย\n",
        "การฝึกโมเดล:\n",
        "\n",
        "ฝึกโมเดลด้วย Optimizer (AdamW) และ Loss Function (CrossEntropyLoss) พร้อมวัดผลบนชุด Validation\n",
        "การประเมินผล:\n",
        "\n",
        "ใช้ classification_report เพื่อวัดเมตริก เช่น Precision, Recall และ F1-score"
      ],
      "metadata": {
        "id": "DKbezXApw_27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :0. อ่านข้อมูลภาพและสร้าง label จากชื่อโฟลเดอร์"
      ],
      "metadata": {
        "id": "YVMgyuIl4sUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :1. การเตรียมข้อมูล"
      ],
      "metadata": {
        "id": "THZigaG0xEC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ez_oVZujPMwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ThaiHandwrittenDataset(Dataset):\n",
        "    def __init__(self, data_dirs, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        # อ่านข้อมูลจากแต่ละโฟลเดอร์\n",
        "        for label, folder in enumerate(data_dirs.keys()):\n",
        "            folder_path = data_dirs[folder]\n",
        "            if not os.path.exists(folder_path):\n",
        "                print(f\"Warning: Folder {folder_path} does not exist. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Processing folder: {folder_path}\")\n",
        "\n",
        "            # ตรวจสอบว่าโฟลเดอร์มี subfolders หรือไม่\n",
        "            subfolders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
        "            if not subfolders:\n",
        "                print(f\"Warning: No subfolders found in {folder_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # วนลูปในแต่ละ subfolder (คลาส)\n",
        "            for subfolder in subfolders:\n",
        "                subfolder_path = os.path.join(folder_path, subfolder)\n",
        "                print(f\"Processing subfolder: {subfolder_path}\")\n",
        "\n",
        "                # ตรวจสอบไฟล์ใน subfolder\n",
        "                folder_files = os.listdir(subfolder_path)\n",
        "                print(f\"Files in {subfolder_path}: {folder_files}\")\n",
        "\n",
        "                for img_name in folder_files:\n",
        "                    img_path = os.path.join(subfolder_path, img_name)\n",
        "\n",
        "                    # ข้ามไฟล์ที่ไม่ใช่ไฟล์จริง\n",
        "                    if not os.path.isfile(img_path):\n",
        "                        print(f\"Skipping non-file entry: {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    # กรองเฉพาะไฟล์ภาพที่มีนามสกุลที่รองรับ\n",
        "                    if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        print(f\"Skipping non-image file: {img_name}\")\n",
        "                        continue\n",
        "\n",
        "                    # ตรวจสอบว่าไฟล์เป็นภาพหรือไม่\n",
        "                    try:\n",
        "                        with Image.open(img_path) as img:\n",
        "                            img.verify()  # ตรวจสอบว่าไฟล์สามารถเปิดได้\n",
        "                            self.data.append(img_path)\n",
        "                            self.labels.append(subfolder)  # ใช้ชื่อ subfolder เป็น label\n",
        "                    except (IOError, SyntaxError) as e:\n",
        "                        print(f\"Skipping invalid image file: {img_path}, Error: {e}\")\n",
        "\n",
        "        # เพิ่มดีบักเมื่อไม่มีข้อมูล\n",
        "        if len(self.data) == 0:\n",
        "            print(\"Dataset is empty. Please check the data directories.\")\n",
        "            self.data = None\n",
        "            self.labels = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) if self.data else 0\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not self.data:\n",
        "            raise ValueError(\"Dataset is empty. Cannot access any items.\")\n",
        "\n",
        "        img_path = self.data[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "# การโหลด Dataset\n",
        "data_dirs = {\n",
        "    \"tones\": \"/content/drive/MyDrive/characters_dataset/tones\"\n",
        "}\n",
        "\n",
        "# กำหนด Transform สำหรับการแปลงภาพ\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "try:\n",
        "    dataset = ThaiHandwrittenDataset(data_dirs=data_dirs, transform=transform)\n",
        "    if not dataset.data:\n",
        "        raise ValueError(\"Dataset is empty after processing. Please check the data directories.\")\n",
        "    print(f\"Dataset loaded with {len(dataset)} samples.\")\n",
        "except ValueError as e:\n",
        "    print(e)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jx5L7I6YQQaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ThaiHandwrittenDataset(Dataset):\n",
        "    def __init__(self, data_dir=None, data=None, labels=None, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "        if not self.data or not self.labels:\n",
        "            raise ValueError(\"Data and labels cannot be None.\")\n",
        "\n",
        "        if len(self.data) != len(self.labels):\n",
        "            raise ValueError(\"Data and labels length mismatch.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "\n",
        "# การโหลด Dataset\n",
        "try:\n",
        "    # กำหนด path ของโฟลเดอร์หลัก\n",
        "    data_dir = '/content/drive/MyDrive/characters_dataset/tones'\n",
        "    dataset = ThaiHandwrittenDataset(data_dir=data_dir, transform=None)\n",
        "    if not dataset.data:  # ตรวจสอบว่า dataset มีข้อมูลหรือไม่\n",
        "        raise ValueError(\"Dataset is empty after processing. Please check the data directory.\")\n",
        "    print(f\"Dataset loaded with {len(dataset)} samples.\")\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "\n",
        "# หาก dataset ไม่ว่าง ให้ดำเนินการต่อ\n",
        "if dataset and dataset.data:\n",
        "    # แบ่งข้อมูลเป็น Train และ Test\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "        dataset.data, dataset.labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # กำหนด Transform สำหรับการแปลงภาพ\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    # สร้าง Dataset ใหม่ที่ใช้ Transform และกำหนด data และ labels\n",
        "    train_dataset = ThaiHandwrittenDataset(data=train_data, labels=train_labels, transform=transform)\n",
        "    test_dataset = ThaiHandwrittenDataset(data=test_data, labels=test_labels, transform=transform)\n",
        "\n",
        "    # สร้าง DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    print(\"Example batch from train_loader:\")\n",
        "    for imgs, labels in train_loader:\n",
        "        print(\"Image paths:\", imgs[:5])\n",
        "        print(\"Labels:\", labels[:5])\n",
        "        break\n",
        "else:\n",
        "    print(\"Cannot proceed without a valid dataset.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-AH38gPfZPf8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :2. การสร้าง Train model using Vision Transformers (ViT) และ Test"
      ],
      "metadata": {
        "id": "WZYwv91vxHwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import ViTForImageClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "\n",
        "# ThaiHandwrittenDataset (เหมือนเดิม)\n",
        "class ThaiHandwrittenDataset(Dataset):\n",
        "    def __init__(self, data=None, labels=None, transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "        if not self.data or not self.labels:\n",
        "            raise ValueError(\"Data and labels cannot be None.\")\n",
        "\n",
        "        if len(self.data) != len(self.labels):\n",
        "            raise ValueError(\"Data and labels length mismatch.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "# การปรับขนาดภาพเป็น 224x224\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ปรับขนาดภาพเป็น 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # ใช้ค่า normalization ที่เหมาะสม\n",
        "])\n",
        "\n",
        "# การโหลดข้อมูล\n",
        "data_dir = '/content/drive/MyDrive/characters_dataset/tones'\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "    raise ValueError(f\"Data directory {data_dir} does not exist.\")\n",
        "\n",
        "for label, folder in enumerate(os.listdir(data_dir)):\n",
        "    folder_path = os.path.join(data_dir, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for img_name in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                    img.verify()  # ตรวจสอบว่าไฟล์ภาพถูกต้อง\n",
        "                    data.append(img_path)\n",
        "                    labels.append(label)  # ใช้ index ของ folder เป็น label\n",
        "            except (IOError, SyntaxError):\n",
        "                print(f\"Skipping invalid image file: {img_path}\")\n",
        "\n",
        "# แบ่งข้อมูลเป็น Train และ Test\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# สร้าง Dataset ใหม่ที่ใช้ Transform และกำหนด data และ labels\n",
        "train_dataset = ThaiHandwrittenDataset(data=train_data, labels=train_labels, transform=transform)\n",
        "test_dataset = ThaiHandwrittenDataset(data=test_data, labels=test_labels, transform=transform)\n",
        "\n",
        "# สร้าง DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# โหลด ViT โมเดลจาก HuggingFace\n",
        "vit_model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=len(set(train_labels)))\n",
        "\n",
        "# กำหนด device (CPU/GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vit_model = vit_model.to(device)\n",
        "\n",
        "# กำหนด Loss function และ Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vit_model.parameters(), lr=1e-4)\n",
        "\n",
        "# ตัวแปรสำหรับเก็บข้อมูล loss และ accuracy\n",
        "epoch_losses = []\n",
        "epoch_accuracies = []\n",
        "\n",
        "# ฟังก์ชันสำหรับฝึกโมเดล\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)  # ทำนายผล\n",
        "            loss = criterion(outputs.logits, labels)  # คำนวณ loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = 100 * correct / total\n",
        "        epoch_losses.append(epoch_loss)\n",
        "        epoch_accuracies.append(epoch_accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}%\")\n",
        "\n",
        "        # Classification Report\n",
        "        if epoch == num_epochs - 1:\n",
        "            report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "            report_df = pd.DataFrame(report).transpose()\n",
        "            report_df.to_excel(f\"classification_report_epoch_{epoch+1}.xlsx\")\n",
        "\n",
        "# ฟังก์ชันสำหรับทดสอบโมเดล\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)  # ทำนายผล\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}%\")\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_df.to_excel(f\"test_classification_report.xlsx\")\n",
        "\n",
        "# เริ่มการฝึกโมเดล\n",
        "num_epochs = 5\n",
        "train_model(vit_model, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
        "\n",
        "# ทดสอบโมเดล\n",
        "test_model(vit_model, test_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "VSJc6NtAzg7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# บันทึกโมเดลหลังจากฝึก\n",
        "torch.save(vit_model.state_dict(), 'vit_model_checkpoint_tones.pth')\n"
      ],
      "metadata": {
        "id": "hIaSKPBMWb12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดโมเดลเพื่อฝึกต่อ\n",
        "vit_model.load_state_dict(torch.load('vit_model_checkpoint_tones.pth'))"
      ],
      "metadata": {
        "id": "lHxqWPoJXLxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :4. กราฟแสดงผลลัพธ์:"
      ],
      "metadata": {
        "id": "BEavFbqZyBH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ฟังก์ชันสำหรับสร้างกราฟ\n",
        "def plot_results():\n",
        "    # Loss graph\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, label='Training Loss', color='blue')\n",
        "    plt.title('Loss per Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"loss_per_epoch.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy graph\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, len(epoch_accuracies) + 1), epoch_accuracies, label='Training Accuracy', color='green')\n",
        "    plt.title('Accuracy per Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"accuracy_per_epoch.png\")\n",
        "    plt.show()\n",
        "\n",
        "# สร้างกราฟการฝึก\n",
        "plot_results()\n"
      ],
      "metadata": {
        "id": "72ziqE0n-JnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :5 Save Graph"
      ],
      "metadata": {
        "id": "0EhbKXLszDPk"
      }
    }
  ]
}